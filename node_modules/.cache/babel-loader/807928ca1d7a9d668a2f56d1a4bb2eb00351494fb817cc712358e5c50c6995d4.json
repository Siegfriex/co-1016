{"ast":null,"code":"// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nimport { APIResource } from \"../../resource.mjs\";\nexport class GraderModels extends APIResource {}","map":{"version":3,"names":["APIResource","GraderModels"],"sources":["C:\\co-1016\\node_modules\\openai\\src\\resources\\graders\\grader-models.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\r\n\r\nimport { APIResource } from '../../resource';\r\nimport * as ResponsesAPI from '../responses/responses';\r\n\r\nexport class GraderModels extends APIResource {}\r\n\r\n/**\r\n * A LabelModelGrader object which uses a model to assign labels to each item in\r\n * the evaluation.\r\n */\r\nexport interface LabelModelGrader {\r\n  input: Array<LabelModelGrader.Input>;\r\n\r\n  /**\r\n   * The labels to assign to each item in the evaluation.\r\n   */\r\n  labels: Array<string>;\r\n\r\n  /**\r\n   * The model to use for the evaluation. Must support structured outputs.\r\n   */\r\n  model: string;\r\n\r\n  /**\r\n   * The name of the grader.\r\n   */\r\n  name: string;\r\n\r\n  /**\r\n   * The labels that indicate a passing result. Must be a subset of labels.\r\n   */\r\n  passing_labels: Array<string>;\r\n\r\n  /**\r\n   * The object type, which is always `label_model`.\r\n   */\r\n  type: 'label_model';\r\n}\r\n\r\nexport namespace LabelModelGrader {\r\n  /**\r\n   * A message input to the model with a role indicating instruction following\r\n   * hierarchy. Instructions given with the `developer` or `system` role take\r\n   * precedence over instructions given with the `user` role. Messages with the\r\n   * `assistant` role are presumed to have been generated by the model in previous\r\n   * interactions.\r\n   */\r\n  export interface Input {\r\n    /**\r\n     * Text inputs to the model - can contain template strings.\r\n     */\r\n    content: string | ResponsesAPI.ResponseInputText | Input.OutputText;\r\n\r\n    /**\r\n     * The role of the message input. One of `user`, `assistant`, `system`, or\r\n     * `developer`.\r\n     */\r\n    role: 'user' | 'assistant' | 'system' | 'developer';\r\n\r\n    /**\r\n     * The type of the message input. Always `message`.\r\n     */\r\n    type?: 'message';\r\n  }\r\n\r\n  export namespace Input {\r\n    /**\r\n     * A text output from the model.\r\n     */\r\n    export interface OutputText {\r\n      /**\r\n       * The text output from the model.\r\n       */\r\n      text: string;\r\n\r\n      /**\r\n       * The type of the output text. Always `output_text`.\r\n       */\r\n      type: 'output_text';\r\n    }\r\n  }\r\n}\r\n\r\n/**\r\n * A MultiGrader object combines the output of multiple graders to produce a single\r\n * score.\r\n */\r\nexport interface MultiGrader {\r\n  /**\r\n   * A formula to calculate the output based on grader results.\r\n   */\r\n  calculate_output: string;\r\n\r\n  graders: Record<\r\n    string,\r\n    StringCheckGrader | TextSimilarityGrader | PythonGrader | ScoreModelGrader | LabelModelGrader\r\n  >;\r\n\r\n  /**\r\n   * The name of the grader.\r\n   */\r\n  name: string;\r\n\r\n  /**\r\n   * The object type, which is always `multi`.\r\n   */\r\n  type: 'multi';\r\n}\r\n\r\n/**\r\n * A PythonGrader object that runs a python script on the input.\r\n */\r\nexport interface PythonGrader {\r\n  /**\r\n   * The name of the grader.\r\n   */\r\n  name: string;\r\n\r\n  /**\r\n   * The source code of the python script.\r\n   */\r\n  source: string;\r\n\r\n  /**\r\n   * The object type, which is always `python`.\r\n   */\r\n  type: 'python';\r\n\r\n  /**\r\n   * The image tag to use for the python script.\r\n   */\r\n  image_tag?: string;\r\n}\r\n\r\n/**\r\n * A ScoreModelGrader object that uses a model to assign a score to the input.\r\n */\r\nexport interface ScoreModelGrader {\r\n  /**\r\n   * The input text. This may include template strings.\r\n   */\r\n  input: Array<ScoreModelGrader.Input>;\r\n\r\n  /**\r\n   * The model to use for the evaluation.\r\n   */\r\n  model: string;\r\n\r\n  /**\r\n   * The name of the grader.\r\n   */\r\n  name: string;\r\n\r\n  /**\r\n   * The object type, which is always `score_model`.\r\n   */\r\n  type: 'score_model';\r\n\r\n  /**\r\n   * The range of the score. Defaults to `[0, 1]`.\r\n   */\r\n  range?: Array<number>;\r\n\r\n  /**\r\n   * The sampling parameters for the model.\r\n   */\r\n  sampling_params?: unknown;\r\n}\r\n\r\nexport namespace ScoreModelGrader {\r\n  /**\r\n   * A message input to the model with a role indicating instruction following\r\n   * hierarchy. Instructions given with the `developer` or `system` role take\r\n   * precedence over instructions given with the `user` role. Messages with the\r\n   * `assistant` role are presumed to have been generated by the model in previous\r\n   * interactions.\r\n   */\r\n  export interface Input {\r\n    /**\r\n     * Text inputs to the model - can contain template strings.\r\n     */\r\n    content: string | ResponsesAPI.ResponseInputText | Input.OutputText;\r\n\r\n    /**\r\n     * The role of the message input. One of `user`, `assistant`, `system`, or\r\n     * `developer`.\r\n     */\r\n    role: 'user' | 'assistant' | 'system' | 'developer';\r\n\r\n    /**\r\n     * The type of the message input. Always `message`.\r\n     */\r\n    type?: 'message';\r\n  }\r\n\r\n  export namespace Input {\r\n    /**\r\n     * A text output from the model.\r\n     */\r\n    export interface OutputText {\r\n      /**\r\n       * The text output from the model.\r\n       */\r\n      text: string;\r\n\r\n      /**\r\n       * The type of the output text. Always `output_text`.\r\n       */\r\n      type: 'output_text';\r\n    }\r\n  }\r\n}\r\n\r\n/**\r\n * A StringCheckGrader object that performs a string comparison between input and\r\n * reference using a specified operation.\r\n */\r\nexport interface StringCheckGrader {\r\n  /**\r\n   * The input text. This may include template strings.\r\n   */\r\n  input: string;\r\n\r\n  /**\r\n   * The name of the grader.\r\n   */\r\n  name: string;\r\n\r\n  /**\r\n   * The string check operation to perform. One of `eq`, `ne`, `like`, or `ilike`.\r\n   */\r\n  operation: 'eq' | 'ne' | 'like' | 'ilike';\r\n\r\n  /**\r\n   * The reference text. This may include template strings.\r\n   */\r\n  reference: string;\r\n\r\n  /**\r\n   * The object type, which is always `string_check`.\r\n   */\r\n  type: 'string_check';\r\n}\r\n\r\n/**\r\n * A TextSimilarityGrader object which grades text based on similarity metrics.\r\n */\r\nexport interface TextSimilarityGrader {\r\n  /**\r\n   * The evaluation metric to use. One of `fuzzy_match`, `bleu`, `gleu`, `meteor`,\r\n   * `rouge_1`, `rouge_2`, `rouge_3`, `rouge_4`, `rouge_5`, or `rouge_l`.\r\n   */\r\n  evaluation_metric:\r\n    | 'fuzzy_match'\r\n    | 'bleu'\r\n    | 'gleu'\r\n    | 'meteor'\r\n    | 'rouge_1'\r\n    | 'rouge_2'\r\n    | 'rouge_3'\r\n    | 'rouge_4'\r\n    | 'rouge_5'\r\n    | 'rouge_l';\r\n\r\n  /**\r\n   * The text being graded.\r\n   */\r\n  input: string;\r\n\r\n  /**\r\n   * The name of the grader.\r\n   */\r\n  name: string;\r\n\r\n  /**\r\n   * The text being graded against.\r\n   */\r\n  reference: string;\r\n\r\n  /**\r\n   * The type of grader.\r\n   */\r\n  type: 'text_similarity';\r\n}\r\n\r\nexport declare namespace GraderModels {\r\n  export {\r\n    type LabelModelGrader as LabelModelGrader,\r\n    type MultiGrader as MultiGrader,\r\n    type PythonGrader as PythonGrader,\r\n    type ScoreModelGrader as ScoreModelGrader,\r\n    type StringCheckGrader as StringCheckGrader,\r\n    type TextSimilarityGrader as TextSimilarityGrader,\r\n  };\r\n}\r\n"],"mappings":"AAAA;SAESA,WAAW,QAAE;AAGtB,OAAM,MAAOC,YAAa,SAAQD,WAAW","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}