{"ast":null,"code":"import _objectSpread from \"C:/co-1016/node_modules/@babel/runtime/helpers/esm/objectSpread2.js\";\n// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nimport { APIResource } from \"../resource.mjs\";\nimport * as Core from \"../core.mjs\";\nexport class Embeddings extends APIResource {\n  /**\r\n   * Creates an embedding vector representing the input text.\r\n   *\r\n   * @example\r\n   * ```ts\r\n   * const createEmbeddingResponse =\r\n   *   await client.embeddings.create({\r\n   *     input: 'The quick brown fox jumped over the lazy dog',\r\n   *     model: 'text-embedding-3-small',\r\n   *   });\r\n   * ```\r\n   */\n  create(body, options) {\n    const hasUserProvidedEncodingFormat = !!body.encoding_format;\n    // No encoding_format specified, defaulting to base64 for performance reasons\n    // See https://github.com/openai/openai-node/pull/1312\n    let encoding_format = hasUserProvidedEncodingFormat ? body.encoding_format : 'base64';\n    if (hasUserProvidedEncodingFormat) {\n      Core.debug('Request', 'User defined encoding_format:', body.encoding_format);\n    }\n    const response = this._client.post('/embeddings', _objectSpread({\n      body: _objectSpread(_objectSpread({}, body), {}, {\n        encoding_format: encoding_format\n      })\n    }, options));\n    // if the user specified an encoding_format, return the response as-is\n    if (hasUserProvidedEncodingFormat) {\n      return response;\n    }\n    // in this stage, we are sure the user did not specify an encoding_format\n    // and we defaulted to base64 for performance reasons\n    // we are sure then that the response is base64 encoded, let's decode it\n    // the returned result will be a float32 array since this is OpenAI API's default encoding\n    Core.debug('response', 'Decoding base64 embeddings to float32 array');\n    return response._thenUnwrap(response => {\n      if (response && response.data) {\n        response.data.forEach(embeddingBase64Obj => {\n          const embeddingBase64Str = embeddingBase64Obj.embedding;\n          embeddingBase64Obj.embedding = Core.toFloat32Array(embeddingBase64Str);\n        });\n      }\n      return response;\n    });\n  }\n}","map":{"version":3,"names":["APIResource","Core","Embeddings","create","body","options","hasUserProvidedEncodingFormat","encoding_format","debug","response","_client","post","_objectSpread","_thenUnwrap","data","forEach","embeddingBase64Obj","embeddingBase64Str","embedding","toFloat32Array"],"sources":["C:\\co-1016\\node_modules\\openai\\src\\resources\\embeddings.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\r\n\r\nimport { APIResource } from '../resource';\r\nimport * as Core from '../core';\r\n\r\nexport class Embeddings extends APIResource {\r\n  /**\r\n   * Creates an embedding vector representing the input text.\r\n   *\r\n   * @example\r\n   * ```ts\r\n   * const createEmbeddingResponse =\r\n   *   await client.embeddings.create({\r\n   *     input: 'The quick brown fox jumped over the lazy dog',\r\n   *     model: 'text-embedding-3-small',\r\n   *   });\r\n   * ```\r\n   */\r\n  create(\r\n    body: EmbeddingCreateParams,\r\n    options?: Core.RequestOptions<EmbeddingCreateParams>,\r\n  ): Core.APIPromise<CreateEmbeddingResponse> {\r\n    const hasUserProvidedEncodingFormat = !!body.encoding_format;\r\n    // No encoding_format specified, defaulting to base64 for performance reasons\r\n    // See https://github.com/openai/openai-node/pull/1312\r\n    let encoding_format: EmbeddingCreateParams['encoding_format'] =\r\n      hasUserProvidedEncodingFormat ? body.encoding_format : 'base64';\r\n\r\n    if (hasUserProvidedEncodingFormat) {\r\n      Core.debug('Request', 'User defined encoding_format:', body.encoding_format);\r\n    }\r\n\r\n    const response: Core.APIPromise<CreateEmbeddingResponse> = this._client.post('/embeddings', {\r\n      body: {\r\n        ...body,\r\n        encoding_format: encoding_format as EmbeddingCreateParams['encoding_format'],\r\n      },\r\n      ...options,\r\n    });\r\n\r\n    // if the user specified an encoding_format, return the response as-is\r\n    if (hasUserProvidedEncodingFormat) {\r\n      return response;\r\n    }\r\n\r\n    // in this stage, we are sure the user did not specify an encoding_format\r\n    // and we defaulted to base64 for performance reasons\r\n    // we are sure then that the response is base64 encoded, let's decode it\r\n    // the returned result will be a float32 array since this is OpenAI API's default encoding\r\n    Core.debug('response', 'Decoding base64 embeddings to float32 array');\r\n\r\n    return (response as Core.APIPromise<CreateEmbeddingResponse>)._thenUnwrap((response) => {\r\n      if (response && response.data) {\r\n        response.data.forEach((embeddingBase64Obj) => {\r\n          const embeddingBase64Str = embeddingBase64Obj.embedding as unknown as string;\r\n          embeddingBase64Obj.embedding = Core.toFloat32Array(embeddingBase64Str);\r\n        });\r\n      }\r\n\r\n      return response;\r\n    });\r\n  }\r\n}\r\n\r\nexport interface CreateEmbeddingResponse {\r\n  /**\r\n   * The list of embeddings generated by the model.\r\n   */\r\n  data: Array<Embedding>;\r\n\r\n  /**\r\n   * The name of the model used to generate the embedding.\r\n   */\r\n  model: string;\r\n\r\n  /**\r\n   * The object type, which is always \"list\".\r\n   */\r\n  object: 'list';\r\n\r\n  /**\r\n   * The usage information for the request.\r\n   */\r\n  usage: CreateEmbeddingResponse.Usage;\r\n}\r\n\r\nexport namespace CreateEmbeddingResponse {\r\n  /**\r\n   * The usage information for the request.\r\n   */\r\n  export interface Usage {\r\n    /**\r\n     * The number of tokens used by the prompt.\r\n     */\r\n    prompt_tokens: number;\r\n\r\n    /**\r\n     * The total number of tokens used by the request.\r\n     */\r\n    total_tokens: number;\r\n  }\r\n}\r\n\r\n/**\r\n * Represents an embedding vector returned by embedding endpoint.\r\n */\r\nexport interface Embedding {\r\n  /**\r\n   * The embedding vector, which is a list of floats. The length of vector depends on\r\n   * the model as listed in the\r\n   * [embedding guide](https://platform.openai.com/docs/guides/embeddings).\r\n   */\r\n  embedding: Array<number>;\r\n\r\n  /**\r\n   * The index of the embedding in the list of embeddings.\r\n   */\r\n  index: number;\r\n\r\n  /**\r\n   * The object type, which is always \"embedding\".\r\n   */\r\n  object: 'embedding';\r\n}\r\n\r\nexport type EmbeddingModel = 'text-embedding-ada-002' | 'text-embedding-3-small' | 'text-embedding-3-large';\r\n\r\nexport interface EmbeddingCreateParams {\r\n  /**\r\n   * Input text to embed, encoded as a string or array of tokens. To embed multiple\r\n   * inputs in a single request, pass an array of strings or array of token arrays.\r\n   * The input must not exceed the max input tokens for the model (8192 tokens for\r\n   * all embedding models), cannot be an empty string, and any array must be 2048\r\n   * dimensions or less.\r\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)\r\n   * for counting tokens. In addition to the per-input token limit, all embedding\r\n   * models enforce a maximum of 300,000 tokens summed across all inputs in a single\r\n   * request.\r\n   */\r\n  input: string | Array<string> | Array<number> | Array<Array<number>>;\r\n\r\n  /**\r\n   * ID of the model to use. You can use the\r\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\r\n   * see all of your available models, or see our\r\n   * [Model overview](https://platform.openai.com/docs/models) for descriptions of\r\n   * them.\r\n   */\r\n  model: (string & {}) | EmbeddingModel;\r\n\r\n  /**\r\n   * The number of dimensions the resulting output embeddings should have. Only\r\n   * supported in `text-embedding-3` and later models.\r\n   */\r\n  dimensions?: number;\r\n\r\n  /**\r\n   * The format to return the embeddings in. Can be either `float` or\r\n   * [`base64`](https://pypi.org/project/pybase64/).\r\n   */\r\n  encoding_format?: 'float' | 'base64';\r\n\r\n  /**\r\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\r\n   * and detect abuse.\r\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\r\n   */\r\n  user?: string;\r\n}\r\n\r\nexport declare namespace Embeddings {\r\n  export {\r\n    type CreateEmbeddingResponse as CreateEmbeddingResponse,\r\n    type Embedding as Embedding,\r\n    type EmbeddingModel as EmbeddingModel,\r\n    type EmbeddingCreateParams as EmbeddingCreateParams,\r\n  };\r\n}\r\n"],"mappings":";AAAA;SAESA,WAAW,QAAE;OACf,KAAKC,IAAI;AAEhB,OAAM,MAAOC,UAAW,SAAQF,WAAW;EACzC;;;;;;;;;;;;EAYAG,MAAMA,CACJC,IAA2B,EAC3BC,OAAoD;IAEpD,MAAMC,6BAA6B,GAAG,CAAC,CAACF,IAAI,CAACG,eAAe;IAC5D;IACA;IACA,IAAIA,eAAe,GACjBD,6BAA6B,GAAGF,IAAI,CAACG,eAAe,GAAG,QAAQ;IAEjE,IAAID,6BAA6B,EAAE;MACjCL,IAAI,CAACO,KAAK,CAAC,SAAS,EAAE,+BAA+B,EAAEJ,IAAI,CAACG,eAAe,CAAC;;IAG9E,MAAME,QAAQ,GAA6C,IAAI,CAACC,OAAO,CAACC,IAAI,CAAC,aAAa,EAAAC,aAAA;MACxFR,IAAI,EAAAQ,aAAA,CAAAA,aAAA,KACCR,IAAI;QACPG,eAAe,EAAEA;MAA2D;IAC7E,GACEF,OAAO,CACX,CAAC;IAEF;IACA,IAAIC,6BAA6B,EAAE;MACjC,OAAOG,QAAQ;;IAGjB;IACA;IACA;IACA;IACAR,IAAI,CAACO,KAAK,CAAC,UAAU,EAAE,6CAA6C,CAAC;IAErE,OAAQC,QAAqD,CAACI,WAAW,CAAEJ,QAAQ,IAAI;MACrF,IAAIA,QAAQ,IAAIA,QAAQ,CAACK,IAAI,EAAE;QAC7BL,QAAQ,CAACK,IAAI,CAACC,OAAO,CAAEC,kBAAkB,IAAI;UAC3C,MAAMC,kBAAkB,GAAGD,kBAAkB,CAACE,SAA8B;UAC5EF,kBAAkB,CAACE,SAAS,GAAGjB,IAAI,CAACkB,cAAc,CAACF,kBAAkB,CAAC;QACxE,CAAC,CAAC;;MAGJ,OAAOR,QAAQ;IACjB,CAAC,CAAC;EACJ","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}